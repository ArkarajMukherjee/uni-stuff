\documentclass[english,10pt,a4paper,]{article}
\usepackage{amsmath,amsfonts,amssymb,amsthm,latexsym}
\usepackage[T1]{fontenc}
\usepackage{microtype}
\title{\vspace{-2cm}\textbf{Linear Algebra I - Homework problems} \\
\author{Arkaraj Mukherjee}}
\begin{document}
\maketitle
{\it{If problem $\bf{n}$ from $\bf{exercise\_x.pdf}$ is assigned as homework then it will be referred to as $\bf{x.n}$.}}
$\\\noindent\rule{\linewidth}{0.5pt}\linebreak$
$\bf{1.8}\hspace{0.5pt}$ It was already shown in class that $\mathbb C^{\mathbb R}=\{f:\mathbb R\to\mathbb C\}$ forms a vectorspace over $\mathbb R$ with the same operations defined here. We show that $V$ is a subspace and hence a vectorspace itself. For all $\alpha\in\mathbb R$ and $f,g\in V$ then for all $t\in\mathbb R$, $$\overline{(\alpha f+g)(t)}=\overline{\alpha f(t)+g(t)}=\overline{\alpha}\cdot\overline{f(t)}+\overline{g(t)}=\alpha\cdot f(-t)+g(-t)=(\alpha f+g)(-t)$$and thus $\alpha f+g\in V$ and we are done as according to what was discussed in class, $V$ is a subspace if for all $\alpha\in\mathbb R$ and $f,g\in V$ its the case that $\alpha f+g\in V$ too. An example of a function with some non real outputs in $V$ is $f(t)=it.$
$\\\noindent\rule{\linewidth}{0.5pt}\linebreak$
$\bf{2.11}\hspace{0.5pt}$ We have seen that if $A\subseteq B$ are subsets of $V$ then $Sp(A)\subseteq Sp(B)$ and using this if $A,B$ are any subsets of $V$ (not the ones used to state the result earlier) that as $A,B\subseteq A\cup B$ we have that $Sp(A),Sp(B)\subseteq Sp(A\cup B)$ and thus $Sp(A)\cup Sp(B)\subseteq Sp(A\cup B)$ and the second bulleted claim follows similarly from the fact that $A\cap B\subseteq A,B$. The last claim is false, we can take disjoint sets $A,B$ such that $Sp(A)=Sp(B)\neq\{0\}$, for example in $V=\mathbb R^2$ take $A=\{(0,1),(1,0)\}$ and $B=\{(0,-1),(-1,0)\}$.
$\\\bf{2.17}\hspace{0.5pt}$ By definition, if $W_1+W_2=V$ then for all $v\in V$ there are some $w_1\in W_1$ and $w_2\in W_2$ such that $w_1+w_2=W$. We claim that these are unique. Say there are $(w_1,w_2),(u_1,u_2)\in W_1\times W_2$ such that $w_1+w_2=v=u_1+u_2$. Then we see that $w_1+w_2=u_1+u_2$ and thus $W_1\ni w_1-u_1=u_2-w_2\in W_2$ as these are vectorspaces, thus $w_1-u_1,u_2-w_2\in W_1\cap W_2$ as both of these are in both of these subsets. Now as $\{0\}=W_1\cap W_2$ we see that $w_1-u_1=0=w_2-u_2$ thus $w_1=u_1$ and $w_1=u_2$ thus the $w_1,w_2$ we get are unique.
$\\\noindent\rule{\linewidth}{0.5pt}\linebreak$
$\bf{3.9}$ As per the condition on $U$ we see that all $(x_1,x_2,x_3,x_4,x_5)\in U$ can be written in the form $(3x_2,x_2,7x_4,x_4,x_5)$ where $x_2,x_4,x_5\in\mathbb R$. It can be easily seen that $U$ is a subspace via the definiton and it is also spanned by the linearly independant set $\{(3,1,0,0,0),(0,0,7,1,0),(0,0,0,0,1)\}$ and hence this is a basis for $U$.
$\\\bf{3.11}$ If $\alpha\in\mathbb R$ then $\{x_1,x_2+\alpha x_1,\ldots,x_n+\alpha x_1\}$ is linearly independant and hence a basis iff for $\beta_1,\ldots,\beta_n\in\mathbb R$, $$\beta_1 x_1+\beta_2(x_2+\alpha x_1)+\ldots+\beta_n(x_n+\alpha x_1)=0\implies \forall k,\beta_k=0$$we can rewrite this as, $$(\beta_1+\alpha(\beta_2+\ldots+\beta_n))x_1+\beta_2x_2+\ldots+\beta_nx_n=0$$But as $\{x_1,\ldots,x_n\}$ was already a basis and hence linearly independant, we see that, $\beta_1+\alpha(\beta_2+\ldots+\beta_n)=\beta_2=\ldots=\beta_n=0$ and thus $\beta_1=-\alpha(0+\ldots+0)=0$ as well and thus this new set is linearly independant and thus also a basis being of size $n$. Now we can clearly take $\alpha$ large enough and get a basis where all the vectors have all positive coordinates.
$\\\noindent\rule{\linewidth}{0.5pt}\linebreak$
\textbf{4.5} For the only if part we see that if $S\oplus T_1=V=S\oplus T_2$ then $\dim(T_1)=\dim(T_2)=\dim(V)-\dim(S)$ by the modular law. For the sake of contradiction (we will contradict the fact that $T_1\cap T_2=\{0\}$) assume that $\dim S<\dim V/2$, this implies that $\dim T_1=\dim T_2>\dim V/2$. Now take some basis $\{a_1,\ldots,a_m\}$ for $T_1$ and another basis $\{b_1,\ldots,b_m\}$ for $T_2$, we now see that as the set $\{a_1,\ldots,a_m,b_1,\ldots,b_m\}$ has size strictly greater than $2\times\dim V/2=\dim V$ and thus it must be linearly dependant because the size of some linearly independant set is atmost that of some spanning set and in this case the basis with $\dim V$ elements spans $V$ so they have size atmost $\dim V$. We can thus find scalars $\alpha_1,\ldots,\alpha_m,\beta_1,\ldots,\beta_m$ not all zero such that 
$$\sum_{i=1}^m\alpha_ia_i+\sum_{i=1}^m\beta_ib_i=0\implies T_1\ni\sum_{i=1}^m\alpha_ia_i=\sum_{i=1}^m(-\beta_i)b_i\in T_2.$$ 
Here not all the scalars are zero so wlog say $\alpha_1\neq 0$, now this implies that the left side isn't zero itself as otherwise we would contradict the linear independance of elements of the basis of $T_1$ i.e. $\{a_1,\ldots,a_m\}$. Thus we found a nonzero vector $v=\sum_{i=1}^m\alpha_ia_i\in T_1\cap T_2$ which contradicts the fact that $T_1\cap T_2=\{0\}.$ From this we have that $\dim T_1=\dim T_2\leq\dim V/2$ which implies that $\dim S=\dim V-\dim T_1\geq \dim V/2.$ 

For the if part we will provide a construction of such $T_1$ and $T_2.$ First take some basis $\{v_1,\ldots,v_n\}$ for $S$ and extend it to a basis $\{v_1,\ldots,v_n,\ldots,v_{n+m}\}$ where $m(\leq n)$ might be zero, in which case taking $T_1=T_2=\{0\}$ suffices as $S$ is the whole space anyways and all the conditions hold. Now assume $m\geq 1$ and let $T_1$ be the subspace spanned by $\{v_{n+1},\ldots,v_{n+m}\}$. We can see that $T_1+S$ is clearly $V$. Now we prove that $T_1\cap S=\{0\}$. If we had some vector $v=\sum_{i=1}^n\alpha_iv_i=\sum_{i=n+1}^{n+m}\beta_iv_i\in S\cap T_1$ then 
$$\sum_{i=1}^n\alpha_iv_i+\sum_{j=n+1}^{n+m}(-\beta_j)v_j=0\implies\alpha_1=\ldots=\alpha_n=-\beta_{n+1}=\ldots=-\beta_{n+m}=0$$ 
by the linear independance of $\{v_1,\ldots,v_{n+m}\}$ as its a basis. This implies that $v=\sum_{i=1}^n\alpha_iv_i=\sum_{i=1}^n0\cdot v_i=\sum_{i=1}^n0=0$ and thus $S\cap T_1=\{0\}$ so by the definition of a direct sum, $S\oplus T_1=V.$ 

Now we claim that, the subspace $T_2$ spanned by $\{v_{n+1}+v_1,\ldots,v_{n+m}+v_m\}$ is also a complement of $S$ and that $T_1\cap T_2=\{0\}$. First we check that $S+T_2=V$. Take any vector $v=\sum_{k=1}^{n+m}\alpha_kv_k\in V$. Then we can rewrite this vector as  
$$\sum_{k=1}^m(\alpha_k-\alpha_{n+k})v_k+\sum_{m<k\leq n}\alpha_kv_k+\sum_{k=n+1}^{n+m}\alpha_k(v_k+v_{k-n}).$$ 
The first two sums are in $S$ and the last sum is in $T_2$, so every vector of $V$ can be expressed as an element of $S+T_2$, which shows that $S+T_2=V$.  

Now we check $S\cap T_2=\{0\}$. Suppose $x\in S\cap T_2$. Then we can write $x$ in two ways, once as $x=\sum_{i=1}^n\alpha_iv_i$ since $x\in S$ and again as $x=\sum_{k=1}^m\gamma_k(v_{n+k}+v_k)$ since $x\in T_2$. Comparing the coefficients in the basis $\{v_1,\ldots,v_{n+m}\}$ we see that for $v_{n+k}$ we must have $\gamma_k=0$ for all $k=1,\ldots,m$. Putting these back into the second expression we get $x=0$. Hence $S\cap T_2=\{0\}$.  

Finally we check $T_1\cap T_2=\{0\}$. Suppose $y\in T_1\cap T_2$. Then $y=\sum_{k=1}^m\beta_kv_{n+k}$ since $y\in T_1$ and also $y=\sum_{k=1}^m\gamma_k(v_{n+k}+v_k)$ since $y\in T_2$. Comparing coefficients of $v_k$ gives $\gamma_k=0$ for all $k=1,\ldots,m$, and thus the right hand side becomes $y=\sum_{k=1}^m0\cdot(v_{n+k}+v_k)=0$. Therefore $y=0$ and $T_1\cap T_2=\{0\}$.  

Thus we have shown that $S\oplus T_2=V$ and $T_1\cap T_2=\{0\}$ as required.
\end{document}